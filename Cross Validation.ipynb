{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59022340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,BatchNormalization,Activation, Flatten, \\\n",
    "Conv3D,MaxPooling3D,Input,GlobalAveragePooling3D, Conv2D, MaxPooling2D,LSTM,TimeDistributed, \\\n",
    "Conv1D,MaxPooling1D,Input, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model,X_test,y_test,type_cm,display_labels,cmap=plt.cm.Blues,normalize=True):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    c_mat = confusion_matrix(y_test,y_pred)\n",
    "    if normalize:\n",
    "        c_mat = np.round(c_mat.astype('float') / c_mat.sum(axis=1)[:, np.newaxis],4)\n",
    "    plt.imshow(c_mat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix'+type_cm)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(display_labels))\n",
    "    plt.xticks(tick_marks, display_labels, rotation=0)\n",
    "    plt.yticks(tick_marks, display_labels)\n",
    "    thresh = c_mat.max() / 2.\n",
    "    for i, j in itertools.product(range(c_mat.shape[0]), range(c_mat.shape[1])):\n",
    "        plt.text(j, i, c_mat[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if c_mat[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "def disp_confusion_matrix(model,X,y,type_cm,class_label):\n",
    "    disp = plot_confusion_matrix(model, X, y, type_cm,display_labels=class_label,\n",
    "                                 cmap=plt.cm.Blues)\n",
    "    \n",
    "def results(lr,model,model_name,epochs=100,verb=1,batch_size=30):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "    history = model.fit(X_train,y_train, epochs = epochs, batch_size=batch_size,\\\n",
    "                        shuffle=False, verbose=verb,validation_data=(X_test,y_test))\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Costo vs Época')\n",
    "    plt.ylabel('Costo')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(['Entrenamiento', 'Validación'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Precisión del modelo')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(['Entrenamiento', 'Validación'], loc='upper right')\n",
    "    plt.show()\n",
    "    disp_confusion_matrix(model,X_test,y_test,model_name,class_label=['Left Hand','Right Hand','Neutral']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70fe520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_val(model,X,y,n_splits,model_epochs,model_batch_size):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits,shuffle=False)\n",
    "    cvscores = []\n",
    "    y = np.argmax(y,axis=1)+1\n",
    "#     print(y)\n",
    "    for train,test in kfold.split(X,y):\n",
    "        y_train =tf.keras.utils.to_categorical(y[train]-1)\n",
    "        y_test =tf.keras.utils.to_categorical(y[test]-1)\n",
    "        print(X[train].shape)\n",
    "        print(X[test].shape)\n",
    "        #Compile the model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        #Fit the model on the train split\n",
    "        model.fit(X[train],y_train,verbose=0,epochs=model_epochs,batch_size=model_batch_size)\n",
    "        #Evaluate the model\n",
    "        score = model.evaluate(X[test],y_test,verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "        cvscores.append(score[1]*100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    return cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dffc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset):\n",
    "    if dataset == 'cwt':\n",
    "        path ='Pre-Dat/Fp1-F3-P4-O2-A1-T3'\n",
    "        extension = ''\n",
    "        X_train = np.load(path+'/X_train'+f'{extension}.npy')\n",
    "        X_test = np.load(path+'/X_test'+f'{extension}.npy')\n",
    "        y_train = np.load(path+'/y_train'+f'{extension}.npy')\n",
    "        y_test = np.load(path+'/y_test'+f'{extension}.npy')\n",
    "    elif dataset == 'raw_1':\n",
    "        path ='Pre-Dat/Raw/Fp1-Fp2-F3-F4-C3-C4-P3-P4-O1-O2-A1-A2-F7-F8-T3-T4-T5-T6-Fz-Cz-Pz'\n",
    "        extension = ''\n",
    "        X_train = np.load(path+'/X_train'+f'{extension}.npy')\n",
    "        X_test = np.load(path+'/X_test'+f'{extension}.npy')\n",
    "        y_train = np.load(path+'/y_train'+f'{extension}.npy')\n",
    "        y_test = np.load(path+'/y_test'+f'{extension}.npy')\n",
    "    elif dataset =='raw_2':\n",
    "        path ='Pre-Dat/Raw/Fp1-Fp2-F3-F4-C3-C4-P3-P4-O1-O2-A1-A2-F7-F8-T3-T4-T5-T6-Fz-Cz-Pz'\n",
    "        extension = ''\n",
    "        X_train = np.load(path+'/X_train'+f'{extension}.npy')\n",
    "        X_test = np.load(path+'/X_test'+f'{extension}.npy')\n",
    "        y_train = np.load(path+'/y_train'+f'{extension}.npy')\n",
    "        y_test = np.load(path+'/y_test'+f'{extension}.npy')\n",
    "        n_steps, n_length,n_features = 8, 25,X_train.shape[2]\n",
    "        X_train = X_train.reshape([X_train.shape[0],n_steps,n_length,n_features])\n",
    "        X_test = X_test.reshape([X_test.shape[0],n_steps,n_length,n_features])\n",
    "    elif dataset == 'ssa_1':\n",
    "        path ='Pre-Dat/SSA/Fp1-F3-P4-O2-A1-T3'\n",
    "        extension = ''\n",
    "        X_train = np.load(path+'/X_train'+f'{extension}.npy')\n",
    "        X_test = np.load(path+'/X_test'+f'{extension}.npy')\n",
    "        y_train = np.load(path+'/y_train'+f'{extension}.npy')\n",
    "        y_test = np.load(path+'/y_test'+f'{extension}.npy')        \n",
    "    elif dataset =='ssa_2':\n",
    "        path ='Pre-Dat/SSA/Fp1-F3-P4-O2-A1-T3'\n",
    "        extension = ''\n",
    "        X_train = np.load(path+'/X_train'+f'{extension}.npy')\n",
    "        X_test = np.load(path+'/X_test'+f'{extension}.npy')\n",
    "        y_train = np.load(path+'/y_train'+f'{extension}.npy')\n",
    "        y_test = np.load(path+'/y_test'+f'{extension}.npy')\n",
    "        n_steps, n_length,n_features = 8, 25,X_train.shape[2]\n",
    "        X_train = X_train.reshape([X_train.shape[0],n_steps,n_length,n_features])\n",
    "        X_test = X_test.reshape([X_test.shape[0],n_steps,n_length,n_features])\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773112da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class models:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def LSTM_model_ssa(self,n_steps=200,n_features=6,activation='tanh',dense_activation='hard_sigmoid',dropout_rate=0.5,batch_normalization=True,init_mode='glorot_normal'):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(n_steps,n_features)))\n",
    "        model.add(LSTM(150,activation=activation,return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(LSTM(150,activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(150,kernel_initializer=init_mode))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(150, kernel_initializer=init_mode))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(3,activation='softmax',kernel_initializer=init_mode,kernel_regularizer=keras.regularizers.l2(l=0.01)))\n",
    "        return model\n",
    "    def CNN_LSTM_model_ssa (self,filters=64,neurons=150,dropout_rate=0.2,conv_activation='softmax',dense_activation='linear'\\\n",
    "                           ,n_steps=8,n_features=6,activation='tanh', init_mode='glorot_normal',lr=1e-3,batch_normalization=True,n_length=25):\n",
    "        model = Sequential()\n",
    "        #CNN\n",
    "        model.add(TimeDistributed(Conv1D(filters=filters,kernel_size=2, activation=conv_activation),input_shape=(None,n_length,n_features)))\n",
    "        model.add(TimeDistributed(Conv1D(filters=filters,kernel_size=2, activation=conv_activation)))\n",
    "        if batch_normalization:\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(Dropout(dropout_rate)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        #LSTM\n",
    "        model.add(LSTM(neurons,activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization()) \n",
    "        #Dense\n",
    "        model.add(Dense(neurons,kernel_initializer=init_mode))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(neurons, kernel_initializer=init_mode))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        #Decision\n",
    "        model.add(Dense(3,activation='softmax',kernel_regularizer=keras.regularizers.l2(l=0.01)))\n",
    "        return model\n",
    "    def LSTM_model_raw (self,n_steps=200,n_features=21,activation='tanh',dense_activation='hard_sigmoid',dropout_rate=0.5,batch_normalization=True,init_mode='glorot_normal'):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(n_steps,n_features)))\n",
    "        model.add(LSTM(150,activation=activation,return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(LSTM(150,activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(150,kernel_initializer=init_mode))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(150, kernel_initializer=init_mode))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(3,activation='softmax',kernel_initializer=init_mode,kernel_regularizer=keras.regularizers.l2(l=0.01)))\n",
    "        return model\n",
    "    def CNN_LSTM_model_raw (self,filters=128,neurons=200,dropout_rate=0.5,conv_activation='softmax',dense_activation='hard_sigmoid'\\\n",
    "                           ,n_steps=8,n_features=21,activation='tanh', init_mode='glorot_normal',lr=1e-3,batch_normalization=True,n_length=25):\n",
    "        model = Sequential()\n",
    "        #CNN\n",
    "        model.add(TimeDistributed(Conv1D(filters=filters,kernel_size=2, activation=conv_activation),input_shape=(None,n_length,n_features)))\n",
    "        if batch_normalization:\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(Conv1D(filters=filters,kernel_size=2, activation=conv_activation)))\n",
    "        if batch_normalization:\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        #LSTM\n",
    "        model.add(LSTM(neurons,activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization()) \n",
    "        #Dense\n",
    "        model.add(Dense(neurons,kernel_initializer=init_mode,bias_initializer='zeros'))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(neurons, kernel_initializer=init_mode,bias_initializer='zeros'))\n",
    "        model.add(Activation(dense_activation))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        #Decision\n",
    "        model.add(Dense(3,activation='softmax',kernel_regularizer=keras.regularizers.l2(l=0.001)))\n",
    "        return model\n",
    "\n",
    "    def CNN(self,width=90, height=300, depth=6,activation='sigmoid',dense_activation='sigmoid',dropout_rate=0.3,NORM=True):\n",
    "        \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Input((width, height, depth, 1)))\n",
    "\n",
    "        model.add(Conv3D(filters=72, kernel_size=7,padding='same',activation=activation))\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "        if NORM:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv3D(filters=128, kernel_size=3,padding='valid',activation=activation))\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "        if NORM:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv3D(filters=256, kernel_size=3,padding='same',activation=activation))\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "        if NORM:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv3D(filters=256, kernel_size=3,padding='same',activation=activation))\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "        if NORM:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv3D(filters=72, kernel_size=3,padding='same',activation=activation))\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "        if NORM:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv3D(filters=72, kernel_size=3,padding='same',activation=activation))\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "        if NORM:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        units_in = 512\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=units_in, activation=dense_activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(units=int(units_in/2), activation=dense_activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(units=int(units_in/4), activation=dense_activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(units=int(units_in/16), activation='tanh'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(units=3,kernel_regularizer=tf.keras.regularizers.l2(l=0.001)))\n",
    "        model.add(Activation('softmax',name='CNN_EEGModel'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e524f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selector(model_id):\n",
    "    if model_id == 'cwt':\n",
    "        model = models().CNN()\n",
    "    elif model_id == 'raw_lstm':\n",
    "        model = models().LSTM_model_raw()\n",
    "    elif model_id == 'raw_lstm_cnn':\n",
    "        model = models().CNN_LSTM_model_raw()\n",
    "    elif model_id == 'ssa_lstm':\n",
    "        model = models().LSTM_model_ssa()\n",
    "    elif model_id == 'ssa_lstm_cnn':\n",
    "        model = models().CNN_LSTM_model_ssa()  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aa220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_key ={\n",
    "#     'cwt':{'key':'cwt','epoch':50,'batch':2},\n",
    "#     'raw_1':{'key':'raw_lstm','epoch':100,'batch':100},\n",
    "#     'ssa_1':{'key':'ssa_lstm','epoch':100,'batch':100},\n",
    "#     'raw_2':{'key':'raw_lstm_cnn','epoch':200,'batch':40},\n",
    "#     'ssa_2':{'key':'ssa_lstm_cnn','epoch':150,'batch':100}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d29a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(model_dictionary):\n",
    "    cv_scores = {}\n",
    "    for key,key_values in model_dictionary.items():\n",
    "        print(key)\n",
    "        X_train,y_train,X_test,y_test = load_dataset(key)\n",
    "        model = model_selector(key_values['key'])\n",
    "        cv_score = kfold_val(model=model,X=X_train,y=y_train,n_splits=8,model_batch_size=key_values['batch'],model_epochs=key_values['epoch'])\n",
    "        cv_scores[key] = (np.mean(cv_score),np.std(cv_score))\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6035a681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_1\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 56.32%\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 74.85%\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 84.04%\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 90.81%\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 94.19%\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 93.75%\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 95.96%\n",
      "(9520, 200, 21)\n",
      "(1360, 200, 21)\n",
      "accuracy: 96.32%\n",
      "85.78% (+/- 13.06%)\n",
      "ssa_1\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 68.90%\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 82.35%\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 88.97%\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 94.56%\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 96.32%\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 95.37%\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 95.81%\n",
      "(9520, 200, 6)\n",
      "(1360, 200, 6)\n",
      "accuracy: 97.35%\n",
      "89.95% (+/- 9.23%)\n",
      "raw_2\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 85.00%\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 94.49%\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 95.96%\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 97.21%\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 97.06%\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 97.28%\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 97.50%\n",
      "(9520, 8, 25, 21)\n",
      "(1360, 8, 25, 21)\n",
      "accuracy: 96.54%\n",
      "95.13% (+/- 3.94%)\n",
      "ssa_2\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 74.41%\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 94.04%\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 96.18%\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 98.24%\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 98.75%\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 98.97%\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 99.04%\n",
      "(9520, 8, 25, 6)\n",
      "(1360, 8, 25, 6)\n",
      "accuracy: 98.24%\n",
      "94.73% (+/- 7.85%)\n"
     ]
    }
   ],
   "source": [
    "model_key ={\n",
    "    'raw_1':{'key':'raw_lstm','epoch':50,'batch':100},\n",
    "    'ssa_1':{'key':'ssa_lstm','epoch':100,'batch':100},\n",
    "    'raw_2':{'key':'raw_lstm_cnn','epoch':100,'batch':40},\n",
    "    'ssa_2':{'key':'ssa_lstm_cnn','epoch':100,'batch':100}\n",
    "}\n",
    "results = worker(model_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ae04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
